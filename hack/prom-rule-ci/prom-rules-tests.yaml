---
rule_files:
  - /tmp/rules.verify

group_eval_order:
  - recordingRules.rules
  - alerts.rules
#information about this format can be found in: https://prometheus.io/docs/prometheus/latest/configuration/unit_testing_rules/
tests:
  # Alerts to test whether our operators are up or not
  - interval: 1m
    input_series:
      - series: 'up{namespace="ci", pod="virt-api-1"}'
        values: "_ _ _ _ _ _ _ _ _ _ _ 0 0 0 0 0 0 1"
      - series: 'up{namespace="ci", pod="virt-controller-1"}'
        values: "_ _ _ _ _ _ _ _ _ _ _ 0 0 0 0 0 0 1"
      - series: 'up{namespace="ci", pod="virt-operator-1"}'
        values: "_ _ _ _ _ _ _ _ _ _ _ 0 0 0 0 0 0 1"

    alert_rule_test:
      # it must not trigger before 10m
      - eval_time: 8m
        alertname: VirtAPIDown
        exp_alerts: []
      - eval_time: 8m
        alertname: VirtControllerDown
        exp_alerts: [ ]
      - eval_time: 8m
        alertname: VirtOperatorDown
        exp_alerts: [ ]
      # it must trigger when there is no data
      - eval_time: 10m
        alertname: VirtAPIDown
        exp_alerts:
          - exp_annotations:
              summary: "All virt-api servers are down."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtAPIDown"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 10m
        alertname: VirtControllerDown
        exp_alerts:
          - exp_annotations:
              summary: "No running virt-controller was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtControllerDown"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 10m
        alertname: VirtOperatorDown
        exp_alerts:
          - exp_annotations:
              summary: "All virt-operator servers are down."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtOperatorDown"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      # it must trigger when operators are not healthy
      - eval_time: 16m
        alertname: VirtAPIDown
        exp_alerts:
          - exp_annotations:
              summary: "All virt-api servers are down."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtAPIDown"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 16m
        alertname: VirtControllerDown
        exp_alerts:
          - exp_annotations:
              summary: "No running virt-controller was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtControllerDown"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 16m
        alertname: VirtOperatorDown
        exp_alerts:
          - exp_annotations:
              summary: "All virt-operator servers are down."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtOperatorDown"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      # it must not trigger when operators are healthy
      - eval_time: 17m
        alertname: VirtAPIDown
        exp_alerts: []
      - eval_time: 17m
        alertname: VirtControllerDown
        exp_alerts: [ ]
      - eval_time: 17m
        alertname: VirtOperatorDown
        exp_alerts: [ ]

    # Alert to test when there are VMIs running on a node with an unready virt-handler pod
    # Alert should not fire for node with no running VMIs.
  - interval: 1m
    input_series:
      - series: 'kube_pod_info{pod="virt-handler-asdf", node="node01"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_status_ready{pod="virt-handler-asdf", condition="true"}'
        values: '0 0 0 0 0 0 0 0 0 0 0'
      - series: 'kube_pod_info{pod="virt-launcher-testvm-123", node="node01"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_info{pod="virt-handler-asdfg", node="node02"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_status_ready{pod="virt-handler-asdfg", condition="true"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_info{pod="virt-launcher-vmi", node="node02"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_info{pod="virt-handler-abcd", node="node03"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_status_ready{pod="virt-handler-abcd", condition="true"}'
        values: '0 0 0 0 0 0 0 0 0 0 0'
      - series: 'kube_pod_info{pod="virt-launcher-novmi", node="node03"}'
        values: '_ _ _ _ _ _ _ _ _ _ _'

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: OrphanedVirtualMachineInstances
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: OrphanedVirtualMachineInstances
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-handler pod detected on node node01 with running vmis for more than 10 minutes"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/OrphanedVirtualMachineInstances"
            exp_labels:
              node: "node01"
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

    # Alert to test when there are VMIs running on a node without a virt-handler pod
    # Alert should not fire for node with no running VMIs.
  - interval: 1m
    input_series:
      - series: 'kube_pod_info{pod="virt-handler-asdf", node="node01"}'
        values: '_ _ _ _ _ _ _ _ _ _ _'
      - series: 'kube_pod_status_ready{pod="virt-handler-asdf", condition="true"}'
        values: '_ _ _ _ _ _ _ _ _ _ _'
      - series: 'kube_pod_info{pod="virt-launcher-testvm-123", node="node01"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_info{pod="virt-handler-asdfg", node="node02"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_status_ready{pod="virt-handler-asdfg", condition="true"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_info{pod="virt-launcher-vmi", node="node02"}'
        values: '1 1 1 1 1 1 1 1 1 1 1'
      - series: 'kube_pod_info{pod="virt-handler-abcd", node="node03"}'
        values: '_ _ _ _ _ _ _ _ _ _ _'
      - series: 'kube_pod_status_ready{pod="virt-handler-abcd", condition="true"}'
        values: '_ _ _ _ _ _ _ _ _ _ _'
      - series: 'kube_pod_info{pod="virt-launcher-novmi", node="node03"}'
        values: '_ _ _ _ _ _ _ _ _ _ _'


    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: OrphanedVirtualMachineInstances
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: OrphanedVirtualMachineInstances
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-handler pod detected on node node01 with running vmis for more than 10 minutes"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/OrphanedVirtualMachineInstances"
            exp_labels:
              node: "node01"
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # Some virt controllers are not ready
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_controller_ready_status{namespace="ci", pod="virt-controller-1"}'
        values: '1+0x11'
      - series: 'kubevirt_virt_controller_ready_status{namespace="ci", pod="virt-controller-2"}'
        values: '0+0x11'
      - series: 'up{namespace="ci", pod="virt-controller-1"}'
        values: '1+0x11'
      - series: 'up{namespace="ci", pod="virt-controller-2"}'
        values: '1+0x11'

    alert_rule_test:
      - eval_time: 10m
        alertname: LowReadyVirtControllersCount
        exp_alerts:
          - exp_annotations:
              summary: "Some virt controllers are running but not ready."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/LowReadyVirtControllersCount"
            exp_labels:
              severity: "warning"
              operator_health_impact: "warning"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All virt controllers are not ready
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_controller_ready_status{namespace="ci", pod="virt-controller-1"}'
        values: "0 0 0 0 0 0 0 0 0 0 0"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: NoReadyVirtController
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: NoReadyVirtController
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-controller was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/NoReadyVirtController"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All virt controllers are not ready (ImagePullBackOff)
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_controller_ready_status{namespace="ci", pod="virt-controller-1"}'
        values: "stale stale stale stale stale stale stale stale stale stale"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: NoReadyVirtController
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: NoReadyVirtController
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-controller was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/NoReadyVirtController"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All virt operators are not ready (ImagePullBackOff)
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_operator_ready_status{namespace="ci", pod="virt-operator-1"}'
        values: "stale stale stale stale stale stale stale stale stale stale"
      - series: 'kube_pod_status_ready{namespace="ci", pod="virt-operator-1"}'
        values: "stale stale stale stale stale stale stale stale stale stale"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: NoReadyVirtOperator
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: NoReadyVirtOperator
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-operator was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/NoReadyVirtOperator"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All virt operators are not ready
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_operator_ready_status{namespace="ci", pod="virt-operator-1"}'
        values: "0x10"
      - series: 'kube_pod_status_ready{namespace="ci", pod="virt-operator-1"}'
        values: "0x10"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: NoReadyVirtOperator
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: NoReadyVirtOperator
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-operator was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/NoReadyVirtOperator"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All virt operators are not ready, according to kubevirt_virt_operator_ready_status
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_operator_ready_status{namespace="ci", pod="virt-operator-1"}'
        values: "0x10"
      - series: 'kube_pod_status_ready{namespace="ci", pod="virt-operator-1"}'
        values: "1x10"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: NoReadyVirtOperator
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: NoReadyVirtOperator
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-operator was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/NoReadyVirtOperator"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All virt operators are not ready, according to kube_pod_status_ready
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_operator_ready_status{namespace="ci", pod="virt-operator-1"}'
        values: "1x10"
      - series: 'kube_pod_status_ready{namespace="ci", pod="virt-operator-1", condition="true"}'
        values: "0x10"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: NoReadyVirtOperator
        exp_alerts: [ ]
      - eval_time: 10m
        alertname: NoReadyVirtOperator
        exp_alerts:
          - exp_annotations:
              summary: "No ready virt-operator was detected for the last 10 min."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/NoReadyVirtOperator"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # virt operator is ready, according to both metrics
  - interval: 1m
    input_series:
      - series: 'kubevirt_virt_operator_ready_status{namespace="ci", pod="virt-operator-1"}'
        values: "1x10"
      - series: 'kube_pod_status_ready{namespace="ci", pod="virt-operator-1", condition="true"}'
        values: "1x10"

    alert_rule_test:
      # no alert at 10 minutes
      - eval_time: 10m
        alertname: NoReadyVirtOperator
        exp_alerts: [ ]


  # Burst REST errors
  # values: '0+10x20' == values: "0 10 20 30 40 ... 190"
  # values: '0+100x20' == values :"0 100 200 .... 1900"
  # so now for EACH POD the total requests should be 10+20+30+..+190+100+200+300+...+1900
  # and the number of requests with error code should be 190+100+200+300+...+1900 which is more than 80% of the total requests
  # in each 5 minutes interval of the test and the error condition(more than 80% of the requests has error code) is true for
  # more than 5 minutes(because each test run for 20 minutes) which should fire an alert for EACH POD
  # values : 0+100x15  0+100x5  ==  :"0 100 200 .... 1400  0 100 200 300 400"  we should treat values : `0+100x20` and
  # values : `0+100x15  0+100x5`  the same way because prometheus counters might reset
  - interval: 1m
    input_series:
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-controller-1", code="200"}'
        values: '0+10x20'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-controller-1", code="400"}'
        values: '0+100x15  0+100x5'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-operator-1", code="200"}'
        values: '0+10x20'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-operator-1", code="400"}'
        values: '0+100x15  0+100x5'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-handler-1", code="200"}'
        values: '0+10x20'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-handler-1", code="500"}'
        values: '0+100x15  0+100x5'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-api-1", code="200"}'
        values: '0+10x20'
      - series: 'kubevirt_rest_client_requests_total{namespace="ci", pod="virt-api-1", code="500"}'
        values: '0+100x15  0+100x5'

    alert_rule_test:
      - eval_time: 20m
        alertname: VirtControllerRESTErrorsBurst
        exp_alerts:
          - exp_annotations:
              summary: "More than 80% of the rest calls failed in virt-controller for the last 5 minutes"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtControllerRESTErrorsBurst"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 20m
        alertname: VirtOperatorRESTErrorsBurst
        exp_alerts:
          - exp_annotations:
              summary: "More than 80% of the rest calls failed in virt-operator for the last 5 minutes"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtOperatorRESTErrorsBurst"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 20m
        alertname: VirtHandlerRESTErrorsBurst
        exp_alerts:
          - exp_annotations:
              summary: "More than 80% of the rest calls failed in virt-handler for the last 5 minutes"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtHandlerRESTErrorsBurst"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
      - eval_time: 20m
        alertname: VirtApiRESTErrorsBurst
        exp_alerts:
          - exp_annotations:
              summary: "More than 80% of the rest calls failed in virt-api for the last 5 minutes"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtApiRESTErrorsBurst"
            exp_labels:
              severity: "critical"
              operator_health_impact: "critical"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"


  # Some nodes without KVM resources
  - interval: 1m
    input_series:
      - series: 'kube_node_status_allocatable{resource="devices_kubevirt_io_kvm", node ="node1"}'
        values: "110 110 110 110 110 110"
      - series: 'kube_node_status_allocatable{resource="devices_kubevirt_io_kvm", node ="node2 "}'
        values: "0 0 0 0 0 0"

    alert_rule_test:
      - eval_time: 5m
        alertname: LowKVMNodesCount
        exp_alerts:
          - exp_annotations:
              description: "Low number of nodes with KVM resource available."
              summary: "At least two nodes with kvm resource required for VM live migration."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/LowKVMNodesCount"
            exp_labels:
              severity: "warning"
              operator_health_impact: "warning"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # All nodes without KVM resources
  - interval: 1m
    input_series:
      - series: 'kube_node_status_allocatable{resource="devices_kubevirt_io_kvm", node ="node1"}'
        values: "0 0 0 0 0 0"
      - series: 'kube_node_status_allocatable{resource="devices_kubevirt_io_kvm", node ="node2 "}'
        values: "0 0 0 0 0 0"

    alert_rule_test:
      - eval_time: 5m
        alertname: LowKVMNodesCount
        exp_alerts:
          - exp_annotations:
              description: "Low number of nodes with KVM resource available."
              summary: "At least two nodes with kvm resource required for VM live migration."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/LowKVMNodesCount"
            exp_labels:
              severity: "warning"
              operator_health_impact: "warning"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"

  # Two nodes with KVM resources
  - interval: 1m
    input_series:
      - series: 'kube_node_status_allocatable{resource="devices_kubevirt_io_kvm", node ="node1"}'
        values: "110 110 110 110 110 110"
      - series: 'kube_node_status_allocatable{resource="devices_kubevirt_io_kvm", node ="node2 "}'
        values: "110 110 110 110 110 110"

    alert_rule_test:
      - eval_time: 5m
        alertname: LowKVMNodesCount
        exp_alerts: []

  # Test recording rule
  - interval: 1m
    input_series:
      - series: 'kube_pod_container_resource_requests{pod="virt-launcher-example-1", namespace="namespace-example-1",container="compute", resource="memory"}'
        # time:  0          1          2          3
        values: "1376882688 1376882688 1376882688 1376882688"
      - series: 'container_memory_working_set_bytes{pod="virt-launcher-example-1", namespace="namespace-example-1",container="compute", resource="memory", prometheus_replica="prometheus-k8s-0"}'
        # time:  0          1          2          3
        values: "1073176576 1073176576 1073176576 1273176576"
      - series: 'container_memory_working_set_bytes{pod="virt-launcher-example-1", namespace="namespace-example-1",container="compute", resource="memory", prometheus_replica="prometheus-k8s-1"}'
        # time:  0          1          2          3
        values: "1073176576 1073176576 1073176576 1273176576"
    promql_expr_test:
      - expr: 'kubevirt_vm_container_free_memory_bytes_based_on_working_set_bytes'
        eval_time: 1m
        exp_samples:
          - labels: 'kubevirt_vm_container_free_memory_bytes_based_on_working_set_bytes{pod="virt-launcher-example-1", namespace="namespace-example-1",container="compute"}'
            value: 303706112
      - expr: 'kubevirt_vm_container_free_memory_bytes_based_on_working_set_bytes'
        eval_time: 3m
        exp_samples:
          - labels: 'kubevirt_vm_container_free_memory_bytes_based_on_working_set_bytes{pod="virt-launcher-example-1", namespace="namespace-example-1",container="compute"}'
            value: 103706112
  # VM eviction strategy is set but vm is not migratable
  - interval: 1m
    input_series:
      - series: 'kubevirt_vmi_info{phase="running", node="node1", namespace="ns-test", name="vm-evict-nonmigratable"}'
        values: "0 0 0 0 1 1 1 1"
      - series: 'kubevirt_vmi_non_evictable{node="node1", namespace="ns-test", name="vm-evict-nonmigratable"}'
        values: "1 1 1 1 1 1 1 1"

    alert_rule_test:
      - eval_time: 1m
        alertname: VMCannotBeEvicted
        exp_alerts: []

      - eval_time: 5m
        alertname: VMCannotBeEvicted
        exp_alerts:
          - exp_annotations:
              description: "Eviction policy for VirtualMachine vm-evict-nonmigratable in namespace ns-test (on node node1) is set to Live Migration but the VM is not migratable"
              summary: "The VM's eviction strategy is set to Live Migration but the VM is not migratable"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VMCannotBeEvicted"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-evict-nonmigratable"
              namespace: "ns-test"
              node: "node1"

  # VM eviction strategy is set and vm is migratable
  - interval: 1m
    input_series:
      - series: 'kubevirt_vmi_info{phase="running", node="node1", namespace="ns-test", name="vm-evict-migratable"}'
        values: "1 1 1 1 1 1 1 1"
      - series: 'kubevirt_vmi_non_evictable{node="node1", namespace="ns-test", name="vm-evict-migratable"}'
        values: "0 0 0 0 0 0 0 0 "

    alert_rule_test:
      - eval_time: 1m
        alertname: VMCannotBeEvicted
        exp_alerts: []

  # Test recording rule for operator memory delta including virt-launcher
  - interval: 1m
    input_series:
      - series: 'container_memory_working_set_bytes{pod="virt-launcher-foo-1", namespace="ns-a", container="compute"}'
        values: '1500 1500'
      - series: 'container_memory_rss{pod="virt-launcher-foo-1", namespace="ns-a", container="compute"}'
        values: '1200 1200'
      - series: 'kube_pod_container_resource_requests{pod="virt-launcher-foo-1", namespace="ns-a", container="compute", resource="memory"}'
        values: '1000 1000'
    promql_expr_test:
      - expr: 'kubevirt_memory_delta_from_requested_bytes{reason="memory_working_set_delta_from_request"}'
        eval_time: 1m
        exp_samples:
          - labels: 'kubevirt_memory_delta_from_requested_bytes{container="compute",namespace="ns-a",pod="virt-launcher-foo-1",reason="memory_working_set_delta_from_request"}'
            value: 500
      - expr: 'kubevirt_memory_delta_from_requested_bytes{reason="memory_rss_delta_from_request"}'
        eval_time: 1m
        exp_samples:
          - labels: 'kubevirt_memory_delta_from_requested_bytes{container="compute",namespace="ns-a",pod="virt-launcher-foo-1",reason="memory_rss_delta_from_request"}'
            value: 200

  # Test recording rule
  - interval: 1m
    input_series:
      # In reality there are many labels on these metrics
      # they are the same except the ones containing vm name like "name" in the example below
      - series: 'kubevirt_vmi_memory_available_bytes{container="virt-handler", name="vm-example-1", namespace="default", node="node-1"}'
        # time:  0          1          2          3
        values: "1376882688 1376882688 1376882688 1376882688"
      - series: 'kubevirt_vmi_memory_available_bytes{container="virt-handler", name="vm-example-2", namespace="default", node="node-1"}'
        # time:  0          1          2          3
        values: "2893266944 2893266944 2893266944 2893266944"
      - series: 'kubevirt_vmi_memory_usable_bytes{container="virt-handler", name="vm-example-1", namespace="default", node="node-1"}'
        # time:  0          1          2          3
        values: "1073176576 1073176576 1073176576 1273176576"
      - series: 'kubevirt_vmi_memory_usable_bytes{container="virt-handler", name="vm-example-2", namespace="default", node="node-1"}'
        # time:  0          1          2          3
        values: "2448936960 2448936960 2448936960 2658936964"
    promql_expr_test:
      - expr: 'kubevirt_vmi_memory_used_bytes'
        eval_time: 1m
        exp_samples:
          - labels: 'kubevirt_vmi_memory_used_bytes{container="virt-handler", name="vm-example-1", namespace="default", node="node-1"}'
            value: 303706112
          - labels: 'kubevirt_vmi_memory_used_bytes{container="virt-handler", name="vm-example-2", namespace="default", node="node-1"}'
            value: 444329984
      - expr: 'kubevirt_vmi_memory_used_bytes'
        eval_time: 3m
        exp_samples:
          - labels: 'kubevirt_vmi_memory_used_bytes{container="virt-handler", name="vm-example-1", namespace="default", node="node-1"}'
            value: 103706112
          - labels: 'kubevirt_vmi_memory_used_bytes{container="virt-handler", name="vm-example-2", namespace="default", node="node-1"}'
            value: 234329980

  # Excessive VMI Migrations in a period of time
  - interval: 1h
    input_series:
      - series: 'kubevirt_vmi_migration_succeeded{vmi="vmi-example-1", namespace="namespace-example-1"}'
        # time:  0 1 2 3 4 5
        values: "_ _ _ 1 7 13"

    alert_rule_test:
      # at 4h, there are total of 11 migrations made on a single VMI, so the alert should not be fired.
      - eval_time: 4h
        alertname: KubeVirtVMIExcessiveMigrations
        exp_alerts: []
      # at 5h, there are total of 13 migrations made on a single VMI, thus the alert is expected to be fired.
      - eval_time: 5h
        alertname: KubeVirtVMIExcessiveMigrations
        exp_alerts:
          - exp_annotations:
              description: "VirtualMachineInstance vmi-example-1 in namespace namespace-example-1 has been migrated more than 12 times during the last 24 hours"
              summary: "An excessive amount of migrations have been detected on a VirtualMachineInstance in the last 24 hours."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtVMIExcessiveMigrations"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              vmi: vmi-example-1
              namespace: namespace-example-1
      - eval_time: 24h
        alertname: KubeVirtVMIExcessiveMigrations
        exp_alerts:
          - exp_annotations:
              description: "VirtualMachineInstance vmi-example-1 in namespace namespace-example-1 has been migrated more than 12 times during the last 24 hours"
              summary: "An excessive amount of migrations have been detected on a VirtualMachineInstance in the last 24 hours."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtVMIExcessiveMigrations"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              vmi: vmi-example-1
              namespace: namespace-example-1
      # will need to evaluate 24h after the alert is triggered to disregard the increases and clear the alert.
      - eval_time: 30h
        alertname: KubeVirtVMIExcessiveMigrations
        exp_alerts: []

  - interval: 1h
    input_series:
    # the same migration is being reported by different virt-controllers
      - series: 'kubevirt_vmi_migration_succeeded{vmi="vmi-example-1", namespace="namespace-example-1"}'
        # time:  0 1 2 3 4 5  6
        values: "_ 1 2 3 8 10 10" # total: 10
      - series: 'kubevirt_vmi_migration_succeeded{vmi="vmi-example-1", namespace="namespace-example-1", vmim="same-migration", pod="virt-controller-1"}'
        # time:  0 1 2 3 4 5 6
        values: "_ _ _ 1 1 1 2"
      - series: 'kubevirt_vmi_migration_succeeded{vmi="vmi-example-1", namespace="namespace-example-1", vmim="same-migration", pod="virt-controller-2"}'
        # time:  0 1 2 3 4 5 6
        values: "_ _ _ 1 1 1 2"
    alert_rule_test:
      # at 5h, there are total of 11 different migrations made on a single VMI, so the alert should not be fired.
      # the two reports by virt-controller-1 and virt-controller-2 for the same migration are being considered as one.
      - eval_time: 5h
        alertname: KubeVirtVMIExcessiveMigrations
        exp_alerts: []
      # at 6h, there are total of 13 different migrations made on a single VMI, so the alert is expected to be fired.
      - eval_time: 6h
        alertname: KubeVirtVMIExcessiveMigrations
        exp_alerts:
          - exp_annotations:
              description: "VirtualMachineInstance vmi-example-1 in namespace namespace-example-1 has been migrated more than 12 times during the last 24 hours"
              summary: "An excessive amount of migrations have been detected on a VirtualMachineInstance in the last 24 hours."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtVMIExcessiveMigrations"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              vmi: vmi-example-1
              namespace: namespace-example-1


  # No nodes are available to host VMs
  - interval: 1m
    input_series:
      - series: 'kube_node_labels{node="node01",label_kubevirt_io_schedulable="true"}'
        values: "_ _ _ _ _ _ _ 1+0x15"
      - series: 'kube_node_status_allocatable{node="node01", resource="devices_kubevirt_io_kvm"}'
        values: "1000+0x15 0+0x7"
      - series: 'kubevirt_configuration_emulation_enabled'
        values: "0+0x22"

    alert_rule_test:
      # has kvm allocatable but no schedulable label
      - eval_time: 6m
        alertname: KubeVirtNoAvailableNodesToRunVMs
        exp_alerts:
          - exp_annotations:
              summary: "There are no available nodes in the cluster to run VMs."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtNoAvailableNodesToRunVMs"
            exp_labels:
              severity: "warning"
              kubernetes_operator_component: "kubevirt"
              kubernetes_operator_part_of: "kubevirt"
              operator_health_impact: "critical"

      # has kvm allocatable and schedulable label
      - eval_time: 7m
        alertname: KubeVirtNoAvailableNodesToRunVMs
        exp_alerts: []

      # has schedulable label but no kvm allocatable nor emulation enabled
      - eval_time: 21m
        alertname: KubeVirtNoAvailableNodesToRunVMs
        exp_alerts:
          - exp_annotations:
              summary: "There are no available nodes in the cluster to run VMs."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtNoAvailableNodesToRunVMs"
            exp_labels:
              severity: "warning"
              kubernetes_operator_component: "kubevirt"
              kubernetes_operator_part_of: "kubevirt"
              operator_health_impact: "critical"

  - interval: 1m
    input_series:
      - series: 'kube_node_labels{node="node01",label_kubevirt_io_schedulable="true"}'
        values: "0+0x7 1+0x14"
      - series: 'kube_node_status_allocatable{node="node01", resource="devices_kubevirt_io_kvm"}'
        values: "0+0x21"
      - series: 'kubevirt_configuration_emulation_enabled'
        values: "0+0x7 1+0x7 0+0x7"

    alert_rule_test:
      # no schedulable label
      - eval_time: 6m
        alertname: KubeVirtNoAvailableNodesToRunVMs
        exp_alerts:
          - exp_annotations:
              summary: "There are no available nodes in the cluster to run VMs."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtNoAvailableNodesToRunVMs"
            exp_labels:
              severity: "warning"
              kubernetes_operator_component: "kubevirt"
              kubernetes_operator_part_of: "kubevirt"
              operator_health_impact: "critical"

      # has schedulable label and emulation enabled
      - eval_time: 8m
        alertname: KubeVirtNoAvailableNodesToRunVMs
        exp_alerts: []

      # has schedulable label, but no kvm allocatable and no emulation enabled
      - eval_time: 21m
        alertname: KubeVirtNoAvailableNodesToRunVMs
        exp_alerts:
          - exp_annotations:
              summary: "There are no available nodes in the cluster to run VMs."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtNoAvailableNodesToRunVMs"
            exp_labels:
              severity: "warning"
              kubernetes_operator_component: "kubevirt"
              kubernetes_operator_part_of: "kubevirt"
              operator_health_impact: "critical"

  # Deprecated APIs being requested.
  - interval: 1m
    input_series:
      - series: 'apiserver_requested_deprecated_apis{resource="virtualmachines", group="kubevirt.io", version="v1alpha3"}'
        values: '0 0 1'
      - series: 'apiserver_request_total{resource="virtualmachines", group="kubevirt.io", version="v1alpha3"}'
        values: '0 0 1 2'

    alert_rule_test:
      - eval_time: 1m
        alertname: KubeVirtDeprecatedAPIRequested
        exp_alerts: []
      - eval_time: 2m
        alertname: KubeVirtDeprecatedAPIRequested
        exp_alerts:
          - exp_annotations:
              description: "Detected requests to the deprecated virtualmachines.kubevirt.io/v1alpha3 API."
              summary: "Detected 1 requests in the last 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtDeprecatedAPIRequested"
            exp_labels:
              severity: "info"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              resource: "virtualmachines"
              group: "kubevirt.io"
              version: "v1alpha3"
      - eval_time: 3m
        alertname: KubeVirtDeprecatedAPIRequested
        exp_alerts:
          - exp_annotations:
              description: "Detected requests to the deprecated virtualmachines.kubevirt.io/v1alpha3 API."
              summary: "Detected 2 requests in the last 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/KubeVirtDeprecatedAPIRequested"
            exp_labels:
              severity: "info"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              resource: "virtualmachines"
              group: "kubevirt.io"
              version: "v1alpha3"
      - eval_time: 13m
        alertname: KubeVirtDeprecatedAPIRequested
        exp_alerts: []


  # VMI CPU Queue higher than 20
  - interval: 1m
    input_series:
      # time:   0   1   2   3
      - series: 'kubevirt_vmi_guest_load_1m{namespace="testns",name="vm1"}'
        values: '0  12  25  5'
      - series: 'kubevirt_vmi_vcpu_seconds_total{namespace="testns",name="vm1",id="0"}'
        values: '0  0   0   0'
      - series: 'kubevirt_vmi_vcpu_seconds_total{namespace="testns",name="vm1",id="1"}'
        values: '0  0   0   0'   # values irrelevant. only series presence counts

    alert_rule_test:
      # at 1m: queue = 12 – 2 = 10  -> below 20
      - eval_time: 1m
        alertname: GuestVCPUQueueHighCritical
        exp_alerts: []

      # at 2m: queue = 25 – 2 = 23  -> alert fires
      - eval_time: 2m
        alertname: GuestVCPUQueueHighCritical
        exp_alerts:
          - exp_annotations:
              description: "VirtualMachineInstance vm1 CPU queue length > 20"
              summary: "Guest vCPU Queue within collection cycle > 20"
              runbook_url: "https://kubevirt.io/monitoring/runbooks/GuestVCPUQueueHighCritical"
            exp_labels:
              severity: "critical"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              namespace: "testns"
              name: "vm1"


      # at3m: queue = 5 – 2 = 3 -> alert clears
      - eval_time: 3m
        alertname: GuestVCPUQueueHighCritical
        exp_alerts: []

  # VM stuck without VMI (early lifecycle states and errors)
  - interval: 1m
    input_series:
      # VMs that SHOULD alert (in problematic states without VMI)
      - series: 'kubevirt_vm_info{name="vm-stuck-provisioning", namespace="test-ns", status="provisioning", status_group="starting"}'
        values: "1x16"
      - series: 'kubevirt_vm_info{name="vm-stuck-starting-no-vmi", namespace="test-ns", status="starting", status_group="starting"}'
        values: "1x16"
      - series: 'kubevirt_vm_info{name="vm-unschedulable", namespace="test-ns", status="ErrorUnschedulable", status_group="error"}'
        values: "1x16"
      - series: 'kubevirt_vm_info{name="vm-pvc-missing", namespace="test-ns", status="ErrorPvcNotFound", status_group="error"}'
        values: "1x16"
      - series: 'kubevirt_vm_info{name="vm-terminating-no-vmi", namespace="test-ns", status="terminating", status_group="non_running"}'
        values: "1x16"
      # VMs that should NOT alert (in healthy states without VMI)
      - series: 'kubevirt_vm_info{name="vm-stopped", namespace="test-ns", status="stopped", status_group="non_running"}'
        values: "1x16"

    alert_rule_test:
      # no alert before 10 minutes
      - eval_time: 9m
        alertname: VirtualMachineStuckInUnhealthyState
        exp_alerts: []
      # alert should fire after 10 minutes only for VMs in problematic states
      - eval_time: 10m
        alertname: VirtualMachineStuckInUnhealthyState
        exp_alerts:
          - exp_annotations:
              summary: "Virtual machine in provisioning state for more than 10 minutes"
              description: "Virtual machine vm-stuck-provisioning in namespace test-ns has been in provisioning state for more than 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckInUnhealthyState"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-stuck-provisioning"
              namespace: "test-ns"
              status: "provisioning"
          - exp_annotations:
              summary: "Virtual machine in starting state for more than 10 minutes"
              description: "Virtual machine vm-stuck-starting-no-vmi in namespace test-ns has been in starting state for more than 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckInUnhealthyState"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-stuck-starting-no-vmi"
              namespace: "test-ns"
              status: "starting"
          - exp_annotations:
              summary: "Virtual machine in ErrorUnschedulable state for more than 10 minutes"
              description: "Virtual machine vm-unschedulable in namespace test-ns has been in ErrorUnschedulable state for more than 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckInUnhealthyState"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-unschedulable"
              namespace: "test-ns"
              status: "ErrorUnschedulable"
          - exp_annotations:
              summary: "Virtual machine in ErrorPvcNotFound state for more than 10 minutes"
              description: "Virtual machine vm-pvc-missing in namespace test-ns has been in ErrorPvcNotFound state for more than 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckInUnhealthyState"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-pvc-missing"
              namespace: "test-ns"
              status: "ErrorPvcNotFound"
          - exp_annotations:
              summary: "Virtual machine in terminating state for more than 10 minutes"
              description: "Virtual machine vm-terminating-no-vmi in namespace test-ns has been in terminating state for more than 10 minutes."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckInUnhealthyState"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-terminating-no-vmi"
              namespace: "test-ns"
              status: "terminating"

  # VM stuck with VMI (runtime states and errors)
  - interval: 1m
    input_series:
      # VMs that SHOULD alert (in problematic states with VMI)
      - series: 'kubevirt_vm_info{name="vm-stuck-starting", namespace="test-ns", status="starting", status_group="starting"}'
        values: "1x11"
      - series: 'kubevirt_vmi_info{name="vm-stuck-starting", namespace="test-ns", node="worker-node-1"}'
        values: "1x11"
      - series: 'kubevirt_vm_info{name="vm-image-error", namespace="test-ns", status="ErrImagePull", status_group="error"}'
        values: "1x11"
      - series: 'kubevirt_vmi_info{name="vm-image-error", namespace="test-ns", node="worker-node-2"}'
        values: "1x11"
      - series: 'kubevirt_vm_info{name="vm-stuck-stopping", namespace="test-ns", status="stopping", status_group="non_running"}'
        values: "1x11"
      - series: 'kubevirt_vmi_info{name="vm-stuck-stopping", namespace="test-ns", node="worker-node-3"}'
        values: "1x11"
      - series: 'kubevirt_vm_info{name="vm-terminating-with-vmi", namespace="test-ns", status="terminating", status_group="non_running"}'
        values: "1x11"
      - series: 'kubevirt_vmi_info{name="vm-terminating-with-vmi", namespace="test-ns", node="worker-node-4"}'
        values: "1x11"
      # VMs that should NOT alert (in healthy states with VMI)
      - series: 'kubevirt_vm_info{name="vm-running", namespace="test-ns", status="running", status_group="running"}'
        values: "1x11"
      - series: 'kubevirt_vmi_info{name="vm-running", namespace="test-ns", node="worker-node-5"}'
        values: "1x11"
      - series: 'kubevirt_vm_info{name="vm-paused", namespace="test-ns", status="paused", status_group="running"}'
        values: "1x11"
      - series: 'kubevirt_vmi_info{name="vm-paused", namespace="test-ns", node="worker-node-6"}'
        values: "1x11"

    alert_rule_test:
      # no alert before 5 minutes
      - eval_time: 4m
        alertname: VirtualMachineStuckOnNode
        exp_alerts: []
      # alerts should fire after 5 minutes only for VMs in problematic states
      - eval_time: 5m
        alertname: VirtualMachineStuckOnNode
        exp_alerts:
          - exp_annotations:
              summary: "Virtual machine stuck in unhealthy state for more than 5 minutes"
              description: "Virtual machine vm-stuck-starting in namespace test-ns on node worker-node-1 has been in starting state for more than 5 minutes. This may indicate issues with the VM lifecycle on the target node."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckOnNode"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-stuck-starting"
              namespace: "test-ns"
              status: "starting"
              node: "worker-node-1"
          - exp_annotations:
              summary: "Virtual machine stuck in unhealthy state for more than 5 minutes"
              description: "Virtual machine vm-image-error in namespace test-ns on node worker-node-2 has been in ErrImagePull state for more than 5 minutes. This may indicate issues with the VM lifecycle on the target node."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckOnNode"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-image-error"
              namespace: "test-ns"
              status: "ErrImagePull"
              node: "worker-node-2"
          - exp_annotations:
              summary: "Virtual machine stuck in unhealthy state for more than 5 minutes"
              description: "Virtual machine vm-stuck-stopping in namespace test-ns on node worker-node-3 has been in stopping state for more than 5 minutes. This may indicate issues with the VM lifecycle on the target node."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckOnNode"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-stuck-stopping"
              namespace: "test-ns"
              status: "stopping"
              node: "worker-node-3"
          - exp_annotations:
              summary: "Virtual machine stuck in unhealthy state for more than 5 minutes"
              description: "Virtual machine vm-terminating-with-vmi in namespace test-ns on node worker-node-4 has been in terminating state for more than 5 minutes. This may indicate issues with the VM lifecycle on the target node."
              runbook_url: "https://kubevirt.io/monitoring/runbooks/VirtualMachineStuckOnNode"
            exp_labels:
              severity: "warning"
              operator_health_impact: "none"
              kubernetes_operator_part_of: "kubevirt"
              kubernetes_operator_component: "kubevirt"
              name: "vm-terminating-with-vmi"
              namespace: "test-ns"
              status: "terminating"
              node: "worker-node-4"
